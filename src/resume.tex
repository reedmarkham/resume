\documentclass{ExpressiveResume}

% ----- Resume -----
\begin{document}

% ----- Name + Contact Information -----
\resumeheader[
    firstname=Reed,
    lastname=Markham,
    email=reedmarkham@gmail.com,
    city=Washington,
    state=DC,
    github=reedmarkham
    ]

% ----- Experience -----
\section{\textbf{Experience}}
\experience{National Council of Architectural Registration Boards}{%
    \role{Data Engineer}{2025 - Present}
    \achievement{
        Integrated vendor \tech{APIs} into 10+ data pipelines using \tech{AWS Glue}, \tech{Python}, and \tech{AWS Redshift} to support the organization's Data team
    }
    \achievement{
        Designed and implemented an ETL process with \tech{AWS Glue} and \tech{Box API} that automated data collection from spreadsheets, reducing time for executive decision-making by 90\%
    }
    \achievement{
        Led migration to \tech{git} for 15+ legacy \tech{Python} scripts and \tech{AWS CloudFormation} templates, checking key data pipelines and infrastructure into version control
    }
    \achievement{
        Built internal Python library implemented across 10+ \tech{AWS Glue} jobs for common \tech{ETL} processes, reducing overall size of codebase by 30\% and adding tests
    }
    \achievement{
        Migrated complex ETL process between \tech{AWS S3}, \tech{AWS Glue}, and \tech{AWS Redshift} to AWS Step Functions orchestration that processes XGB of data daily
    }
    \achievement{
        Designed and implemented \tech{retrieval-augmented generation} tools for Customer Support team, using \tech{AWS Bedrock} and \tech{FastAPI}
    }
    \achievement{
        Audited Data team's \tech{AWS} resources to support account consolidation process, reducing organization expenses by 1\%
    }
    \achievement{
        Architected the organization's data lake and warehouse using \tech{AWS S3}, \tech{AWS Redshift}, and \tech{dbt}
    }
}
\experience{SiriusXM}{%
    \role{Senior Product Analyst}{2017 - 2025}
    \achievement{
        Deployed \tech{AWS SageMaker Studio} for team of 50+ data scientists, using \tech{AWS CDK} for infrastructure-as-code and \tech{GitHub Actions} for \tech{CI/CD}
    } 
    \achievement{
        Led \tech{GitHub Enterprise} onboarding for team of 10+ to enable version control for analytics jobs and notebooks
    }
    \achievement{
        Increased efficiency for business process by 10\%, automating previously-manual data pipelines using \tech{Airflow}, \tech{Hive SQL}, and \tech{PySpark}
    }
    \achievement{
        Recommended \tech{SQL} query optimizations that reduced run times by up to 75\%
    }
    \achievement{
        Analyzed terabytes of data to identify \$1M+ of annual royalty payment savings by improving data quality
    }
    \achievement{
        Built suite of \tech{Tableau} dashboards with 10K+ total views, including development of data pipelines using \tech{Hive SQL}, \tech{BigQuery}, and \tech{Airflow}
    }
    \achievement{
        Developed \tech{Python} libraries to automate analytics workflows on \tech{GCP Dataproc} and \tech{AWS Redshift}
    }
    \achievement{
        Promoted from \textbf{Associate Product Analyst} to \textbf{Product Analyst}, then \textbf{Senior Product Analyst}
    }
    \achievement{
        First \textbf{Product Analytics Intern} converted to full-time \textbf{Associate Product Analyst}
    }
}

% ----- Education -----
\section{\textbf{Education}}
\degree{B.S. Industrial and Systems Engineering, \honors{magna cum laude}}{University of Southern California}{2017}
\achievement{
    Member of USC men's club lacrosse team, 2013 - 2016
}

\end{document}